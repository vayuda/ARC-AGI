{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7e1093-5938-4cb7-b0be-83348213cf7c",
   "metadata": {},
   "source": [
    "# Top-K Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83b87b4-3f14-4568-aae8-5b431f617115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import loader as loader\n",
    "import utility as utility\n",
    "import transformers as transformers\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945b3761-e63b-4f69-8b32-e29ae9025ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_params = {\n",
    "    \"batch_size\": 1,\n",
    "    \"pad_images\": False,\n",
    "    \"percent_mask\": 0.0,\n",
    "    \"shuffle\": True,\n",
    "    \"evaluate\": False,\n",
    "    \"place_central\": True\n",
    "}\n",
    "\n",
    "dataloader = loader.get_dataloader('dict_traindata.txt', loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d173232b-a4fb-4db6-8ff4-4fa16fbf80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding cosine-similarity at top-5 samples:\n",
      "Model:             vit_20241121_124353.pth || Total Accuracy: 0.446 | Avg. Sim: 0.986 | Total Correct Accuracy 0.787\n",
      "Model:             vit_20241121_161413.pth || Total Accuracy: 0.460 | Avg. Sim: 0.990 | Total Correct Accuracy 0.800\n"
     ]
    }
   ],
   "source": [
    "def compute_topk(model_paths, k=5):\n",
    "    print(f\"Embedding cosine-similarity at top-{k} samples:\")\n",
    "    for model_filename in model_paths:\n",
    "        ViT, _ = transformers.VisionTransformer.load_model(f'trained_models/{model_filename}', print_statements=False, device=device)\n",
    "        ViT = ViT.to(device)\n",
    "        \n",
    "        # This will take some time -- it is generating CLS token embeddings for all images in the dataset\n",
    "        ids_list = []\n",
    "        images_tensor = []\n",
    "        cls_tensor = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ViT.eval()\n",
    "            for i, (ids, u, _, _, _, _) in enumerate(dataloader):\n",
    "                B, H, W = u.shape\n",
    "                u = u.to(device)\n",
    "        \n",
    "                cls_logits, _, _ = ViT(u, save_attn=False, temperature=1)        \n",
    "                ids_list.extend(ids)\n",
    "                cls_tensor.append(cls_logits[:, 0].cpu())\n",
    "                \n",
    "            cls_tensor = torch.cat(cls_tensor, dim=0)\n",
    "    \n",
    "        itos = dict([(key, value) for key, value in enumerate(ids_list)])\n",
    "        stoi = dict([(key, value) for value, key in enumerate(ids_list)])\n",
    "    \n",
    "        # Eval pipeline\n",
    "        attempts, correct, tot_correct, avg_sim, nums_checked = 0, 0, 0, 0, 0\n",
    "        for target_id in ids_list:\n",
    "            idx = stoi[target_id]\n",
    "            closest_embeddings, closest_sims = utility.top_k_cosine_similarity(cls_tensor, idx, k+1, largest=True)\n",
    "            target_problem = target_id[:target_id.find('-')]\n",
    "        \n",
    "            attempts += 1\n",
    "            correct_for_round = 0\n",
    "            for i, sim_id_num in enumerate(closest_embeddings):\n",
    "                sim_id = itos[sim_id_num.item()]\n",
    "                if sim_id != target_id:\n",
    "                    avg_sim += closest_sims[i].item()\n",
    "                    nums_checked += 1\n",
    "                    if sim_id[:sim_id.find('-')] == target_problem:\n",
    "                        correct_for_round += 1\n",
    "            tot_correct += correct_for_round\n",
    "            correct += min(correct_for_round, 1) \n",
    "        \n",
    "        print(f\"Model: {model_filename:>35} || Total Accuracy: {correct/attempts:.3f} | Avg. Sim: {avg_sim/nums_checked:.3f} | Total Correct Accuracy {tot_correct/attempts:.3f}\")\n",
    "\n",
    "# pth_files = [file for file in os.listdir('trained_models/') if file.endswith('.pth')]\n",
    "pth_files = ['vit_20241121_124353.pth', 'vit_20241121_161413.pth']\n",
    "compute_topk(pth_files, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e800b88-821e-4bdb-bb91-241a8f06932d",
   "metadata": {},
   "source": [
    "# Evaluate TorchVision Models for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c0264c-02b3-4a63-acf8-1e64676ab46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision.models import squeezenet1_0\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebae0aa-4960-4122-bc36-daf38b7e8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_TO_HEX = {\n",
    "    -1: '#FF6700',  # blaze orange\n",
    "    0:  '#000000',  # black\n",
    "    1:  '#1E93FF',  # blue\n",
    "    2:  '#F93C31',  # orange\n",
    "    3:  '#4FCC30',  # green\n",
    "    4:  '#FFDC00',  # yellow\n",
    "    5:  '#999999',  # grey\n",
    "    6:  '#E53AA3',  # pink\n",
    "    7:  '#FF851B',  # light orange\n",
    "    8:  '#87D8F1',  # cyan\n",
    "    9:  '#921231',  # red\n",
    "    10: '#555555',  # border\n",
    "    11: '#FF6700',  # active grid border\n",
    "    12: '#D2B48C',  # image padding\n",
    "}\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    \"\"\" Convert a hex color to an RGB tuple with values in the range [0, 1]. \"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    return tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (0, 2, 4))\n",
    "\n",
    "def get_embedding(images, encoder, display=True):\n",
    "    assert images.dim() == 4, \"Input images must be a 4D tensor with shape (B x N x H x W).\"\n",
    "    device = next(encoder.parameters()).device\n",
    "    images = images.to(device)  # Move images to the same device as the encoder\n",
    "    batch_size, _, height, width = images.shape\n",
    "    mapped_images = torch.zeros((batch_size, 3, height, width), dtype=torch.float32, device=device)  \n",
    "    for b in range(batch_size):\n",
    "        single_image = images[b, 0]  # Extract single-channel image\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                rgb_color = torch.tensor(hex_to_rgb(COLOR_TO_HEX[int(single_image[y, x])]),\n",
    "                                         dtype=torch.float32, device=device)\n",
    "                mapped_images[b, :, y, x] = rgb_color\n",
    "    resized_images = F.interpolate(mapped_images, size=(224, 224), mode='nearest')\n",
    "    embeddings = encoder(resized_images)\n",
    "    if display:\n",
    "        image_to_display = resized_images[0].permute(1, 2, 0).cpu()  # Move channels to last dimension for display\n",
    "        plt.imshow(image_to_display)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e60992c-000f-4a2d-867d-cb629263257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_models = {\n",
    "    # \"ResNet18\": resnet18,\n",
    "    # \"ResNet50\": resnet50,\n",
    "    # \"MobileNet_v2\": mobilenet_v2,\n",
    "}\n",
    "\n",
    "for model_name, model_fn in torch_models.items():\n",
    "    model = model_fn(pretrained=True)\n",
    "    if \"ResNet\" in model_name:\n",
    "        model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove FC layer\n",
    "    elif \"MobileNet\" in model_name:\n",
    "        model = torch.nn.Sequential(model.features, torch.nn.AdaptiveAvgPool2d((1, 1)))  # Use features, add pooling\n",
    "    elif \"EfficientNet\" in model_name:\n",
    "        model = torch.nn.Sequential(model.features, torch.nn.AdaptiveAvgPool2d((1, 1)))  # Use features, add pooling\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    ids_list = []\n",
    "    images_tensor = []\n",
    "    cls_tensor = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (ids, u, u_masks, v, v_masks, compute_patch) in enumerate(dataloader):\n",
    "            B, H, W = u.shape\n",
    "            u = u.to(device).unsqueeze(0)\n",
    "            embs = get_embedding(u, model, False)\n",
    "            embs = embs.reshape(1, -1)\n",
    "            ids_list.extend(ids)\n",
    "            cls_tensor.append(embs.cpu())\n",
    "        cls_tensor = torch.cat(cls_tensor, dim=0)\n",
    "    \n",
    "    itos = dict([(key, value) for key, value in enumerate(ids_list)])\n",
    "    stoi = dict([(key, value) for value, key in enumerate(ids_list)])\n",
    "    k = 5\n",
    "    \n",
    "    attempts, correct, avg_sim, nums_checked, tot_correct = 0, 0, 0, 0, 0\n",
    "    for target_id in ids_list:\n",
    "        idx = stoi[target_id]\n",
    "        closest_embeddings, closest_sims = utility.top_k_cosine_similarity(cls_tensor, idx, k+1, largest=True)\n",
    "        target_problem = target_id[:target_id.find('-')]\n",
    "    \n",
    "        attempts += 1\n",
    "        correct_for_round = 0\n",
    "        for i, sim_id_num in enumerate(closest_embeddings):\n",
    "            sim_id = itos[sim_id_num.item()]\n",
    "            if sim_id != target_id:\n",
    "                avg_sim += closest_sims[i].item()\n",
    "                nums_checked += 1\n",
    "                if sim_id[:sim_id.find('-')] == target_problem:\n",
    "                    correct_for_round += 1\n",
    "                    \n",
    "        tot_correct += correct_for_round\n",
    "        correct += min(correct_for_round, 1) \n",
    "    \n",
    "    print(f\"Model: {model_name:>25} || Total Accuracy: {correct/attempts:.3f} | Avg. Sim: {avg_sim/nums_checked:.3f} | Total Correct Accuracy {tot_correct/attempts:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
